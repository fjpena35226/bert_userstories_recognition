{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"rnn_Bert_usrecog.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"zhgjdr2Uto6v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612358632681,"user_tz":180,"elapsed":10655,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"c76d9739-8a8f-4fb8-b409-25cdf74073a1"},"source":["!pip install -q tensorflow-hub\n","!pip install -q seaborn\n","!pip install bert-tensorflow\n","\n","%tensorflow_version 1.14"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n","\r\u001b[K     |█████                           | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.4\n","`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.14`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dQbDjic6tAG0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612358654936,"user_tz":180,"elapsed":31108,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"e4743527-115b-4388-ac74-446af35daeed"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!git clone --depth 1 https://github.com/google-research/bert"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Cloning into 'bert'...\n","remote: Enumerating objects: 23, done.\u001b[K\n","remote: Counting objects: 100% (23/23), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 23 (delta 1), reused 21 (delta 1), pack-reused 0\u001b[K\n","Unpacking objects: 100% (23/23), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PV6icbeKuzwg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612358660946,"user_tz":180,"elapsed":10074,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"e4190db8-c7c2-4f25-df97-24a99d4fce47"},"source":["# Import our dependencies\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n","from tensorflow.keras.models import Sequential\n","import pandas as pd\n","import tensorflow_hub as hub\n","import os\n","import re, sys, csv, pickle\n","from keras import backend as K\n","import tensorflow.keras.layers as layers\n","from keras.models import Model, load_model\n","from keras.engine import Layer\n","import numpy as np\n","from numpy import savetxt\n","from pathlib import Path\n","import codecs\n","from sklearn.model_selection import train_test_split\n","from tqdm import trange\n","from tqdm import tqdm\n","import bert\n","from bert.tokenization import FullTokenizer\n","from tqdm import tqdm_notebook\n","from tensorflow.python.keras.backend import set_session\n","from sklearn.utils import shuffle"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8k0InC6uuwnR","executionInfo":{"status":"ok","timestamp":1612358660951,"user_tz":180,"elapsed":7744,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["class PaddingInputExample(object):\n","    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n","    When running eval/predict on the TPU, we need to pad the number of examples\n","    to be a multiple of the batch size, because the TPU requires a fixed batch\n","    size. The alternative is to drop the last batch, which is bad because it means\n","    the entire output data won't be generated.\n","    We use this class instead of `None` because treating `None` as padding\n","    battches could cause silent errors.\n","    \"\"\"\n","\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None):\n","        \"\"\"Constructs a InputExample.\n","    Args:\n","      guid: Unique id for the example.\n","      text_a: string. The untokenized text of the first sequence. For single\n","        sequence tasks, only this sequence must be specified.\n","      text_b: (Optional) string. The untokenized text of the second sequence.\n","        Only must be specified for sequence pair tasks.\n","      label: (Optional) string. The label of the example. This should be\n","        specified for train and dev examples, but not for test examples.\n","    \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.label = label\n","\n","def create_tokenizer_from_hub_module(bert_path):\n","    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","    bert_module =  hub.Module(bert_path)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    vocab_file, do_lower_case = sess.run(\n","        [\n","            tokenization_info[\"vocab_file\"],\n","            tokenization_info[\"do_lower_case\"],\n","        ]\n","    )\n","\n","    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","def convert_single_example(tokenizer, example, max_seq_length=256):\n","    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n","\n","    if isinstance(example, PaddingInputExample):\n","        input_ids = [0] * max_seq_length\n","        input_mask = [0] * max_seq_length\n","        segment_ids = [0] * max_seq_length\n","        label = 0\n","        return input_ids, input_mask, segment_ids, label\n","\n","    tokens_a = tokenizer.tokenize(example.text_a)\n","    if len(tokens_a) > max_seq_length - 2:\n","        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n","\n","    tokens = []\n","    segment_ids = []\n","    tokens.append(\"[CLS]\")\n","    segment_ids.append(0)\n","    for token in tokens_a:\n","        tokens.append(token)\n","        segment_ids.append(0)\n","    tokens.append(\"[SEP]\")\n","    segment_ids.append(0)\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","    # tokens are attended to.\n","    input_mask = [1] * len(input_ids)\n","\n","    # Zero-pad up to the sequence length.\n","    while len(input_ids) < max_seq_length:\n","        input_ids.append(0)\n","        input_mask.append(0)\n","        segment_ids.append(0)\n","\n","    assert len(input_ids) == max_seq_length\n","    assert len(input_mask) == max_seq_length\n","    assert len(segment_ids) == max_seq_length\n","\n","    return input_ids, input_mask, segment_ids, example.label\n","\n","def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n","    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n","\n","    input_ids, input_masks, segment_ids, labels = [], [], [], []\n","    for example in tqdm(examples, desc=\"Converting examples to features\"):\n","        input_id, input_mask, segment_id, label = convert_single_example(\n","            tokenizer, example, max_seq_length\n","        )\n","        input_ids.append(input_id)\n","        input_masks.append(input_mask)\n","        segment_ids.append(segment_id)\n","        labels.append(label)\n","    return (\n","        np.array(input_ids),\n","        np.array(input_masks),\n","        np.array(segment_ids),\n","        np.array(labels).reshape(-1, 1),\n","    )\n","\n","def convert_text_to_examples(texts, labels):\n","    \"\"\"Create InputExamples\"\"\"\n","    InputExamples = []\n","    for text, label in zip(texts, labels):\n","        InputExamples.append(\n","            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n","        )\n","    return InputExamples\n","\n","def convert_test_text_to_examples(texts):\n","    \"\"\"Create InputExamples\"\"\"\n","    InputExamples = []\n","    for text, label in zip(texts, labels):\n","        InputExamples.append(\n","            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=None)\n","        )\n","    return InputExamples"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFKOOyP91I_c","executionInfo":{"status":"ok","timestamp":1612358660954,"user_tz":180,"elapsed":3636,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["#@title Notebook Parameters { run: \"auto\" }\n","\n","#@markdown #### BERT module to Load\n","#@markdown * This will load a particular module from TF Hub\n","\n","BERT_PATH   = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" #@param {type:\"string\"}\n","\n","#@markdown * `TUNE_CELLS` controls how many Transformer cells to finetune\n","#@markdown * Setting a value of `-1` means train entire BERT model\n","#@markdown * The authors recommend finetuning the entire BERT model\n","\n","TUNE_CELLS = 1         #@param {type:\"integer\"}\n","\n","#@markdown #### Dataset to Load\n","\n","DATASET_URL = \"https://deeplearning-mat.s3-ap-southeast-1.amazonaws.com/aclImdb_data.zip\" #@param {type:\"string\"}\n","FILENAME    = \"aclImdb_data.zip\" #@param {type:\"string\"}\n","\n","#@markdown #### Training Parameters\n","\n","MIXED_PRECISION = True #@param [\"True\", \"False\"] {type:\"raw\"}\n","USE_XLA = True         #@param [\"True\", \"False\"] {type:\"raw\"}\n","\n","MAX_SEQ_LEN = 256       #@param {type:\"integer\"}\n","VAL_SPLIT   = 0.3       #@param {type:\"number\"}\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_LukEPstvk-","executionInfo":{"status":"ok","timestamp":1612358661870,"user_tz":180,"elapsed":900,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["env_url = Path('/content/drive/My Drive/TP-final-SI')\n","file_url = env_url/'dataSetUserStoriesRecognition-tunend1.csv'\n","\n","######LOADING FILE\n","csvfile = codecs.open(file_url, 'r', encoding='utf-8', errors='ignore')\n","reader = csv.DictReader(csvfile, delimiter=';')\n","\n","data = []\n","labels = []\n","\n","for row in reader:\n","  data.append(row['Resumen'].lower())\n","  labels.append(int(row['Class'].lower()))\n","\n","#print(len(data))\n","#print(len(labels))\n","csvfile.close()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rECg_7WUs6bp","executionInfo":{"status":"ok","timestamp":1612358662167,"user_tz":180,"elapsed":560,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["del csvfile\n","del reader"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"51cfgTTfiBn6","executionInfo":{"status":"ok","timestamp":1612358663326,"user_tz":180,"elapsed":1002,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["#####SPLIT TRAINING-VALIDATION\n","data_train, data_test, labels_train, labels_test = train_test_split(\n","    data, labels, test_size = 0.3,\n","    train_size = 0.7, shuffle = 1, random_state=42,  stratify=labels\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"t96OoX2yj7cx","executionInfo":{"status":"ok","timestamp":1612358664051,"user_tz":180,"elapsed":795,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["train_text = data_train\n","train_text = [' '.join(t.split()[0:MAX_SEQ_LEN]) for t in train_text]\n","train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n","train_label = labels_train"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWEGAiMlxCgc","executionInfo":{"status":"ok","timestamp":1612358668125,"user_tz":180,"elapsed":2694,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["config = tf.ConfigProto()\n","\n","if USE_XLA:\n","    opt_level = tf.OptimizerOptions.ON_1\n","    tf.enable_resource_variables()\n","else:\n","    opt_level = tf.OptimizerOptions.OFF\n","    \n","config.graph_options.optimizer_options.global_jit_level = opt_level\n","\n","config.graph_options.rewrite_options.auto_mixed_precision = MIXED_PRECISION\n","\n","sess = tf.Session(config=config)\n","tf.keras.backend.set_session(sess)\n","\n","sess = tf.keras.backend.get_session()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZoc0DFfxGpQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612358679694,"user_tz":180,"elapsed":11645,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"8c380067-761e-464a-9c8b-a693cf6b8db8"},"source":["# Instantiate a BERT-specific tokenizer\n","\n","tokenizer = create_tokenizer_from_hub_module(BERT_PATH)\n","\n","# Convert data to InputExample format\n","\n","train_examples = convert_text_to_examples(train_text, train_label)\n","\n","feat = convert_examples_to_features(tokenizer,\n","                                    train_examples,\n","                                    max_seq_length=MAX_SEQ_LEN)\n","\n","(train_input_ids,train_input_masks,train_segment_ids,train_labels) = feat"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Converting examples to features: 100%|██████████| 5597/5597 [00:01<00:00, 3066.64it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6X1WyEzH5Ipa","executionInfo":{"status":"ok","timestamp":1612358679696,"user_tz":180,"elapsed":8657,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["class BERT(tf.keras.layers.Layer):\n","    def __init__(self, finetune_cells, bert_path, debug=False, **kwargs):\n","        self.finetune_cells = finetune_cells\n","        self.trainable = True\n","        self.output_size = 768\n","        self.bert_path = bert_path\n","        self.debug = debug\n","        super(BERT, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.bert = hub.Module(self.bert_path,\n","                               trainable=self.trainable,\n","                               name=\"{}_module\".format(self.name))\n","        \n","        trainable_vars = self.bert.variables\n","\n","        t_vs = [var for var in trainable_vars if not \"/cls/\" in var.name]\n","\n","        trainable_vars = t_vs\n","\n","        layer_name_list = []\n","\n","        for i, var in enumerate(trainable_vars):\n","            if self.debug:\n","                var_shape = var.get_shape()\n","                var_params = 1\n","                for dim in var_shape:\n","                    var_params *= dim\n","                print(str(i), \"-\", \"var:\", var.name)\n","                print(\" \", \"shape:\", var_shape , \"param:\", var_params)\n","                \n","            if \"layer\" in var.name:\n","                layer_name = var.name.split(\"/\")[3]\n","                layer_name_list.append(layer_name)\n","\n","        layer_names = list(set(layer_name_list))\n","        layer_names.sort()\n","\n","        if self.debug:\n","            print(layer_names)\n","\n","        if self.finetune_cells == -1:\n","            for var in trainable_vars:\n","                if \"/pooler/\" in var.name:\n","                    # ignore the undocumented pooling layer\n","                    # we will create our own\n","                    pass\n","                else:\n","                    self._trainable_weights.append(var)\n","\n","        else:\n","            # Select how many layers to fine tune\n","            last_n_layers = len(layer_names) - self.finetune_cells\n","\n","            for var in trainable_vars:\n","                if \"layer\" in var.name:\n","                    layer_name = var.name.split(\"/\")[3]\n","                    layer_num = int(layer_name.split(\"_\")[1])+1\n","                    if layer_num > last_n_layers:\n","                        # Add to trainable weights\n","                        self._trainable_weights.append(var)\n","\n","            if self.debug:\n","                print(\"BERT module loaded with\", len(layer_names),\n","                    \"Transformer cells, training all cells >\", last_n_layers)\n","\n","        # Add non-trainable weights\n","        for var in self.bert.variables:\n","            if var not in self._trainable_weights:\n","                self._non_trainable_weights.append(var)\n","\n","        super(BERT, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        input_ids, input_mask, segment_ids = inputs\n","        bert_inputs = dict(input_ids=tf.cast(input_ids, dtype=\"int32\"),\n","                           input_mask=tf.cast(input_mask, dtype=\"int32\"),\n","                           segment_ids=tf.cast(segment_ids, dtype=\"int32\"))\n","        result = self.bert(inputs=bert_inputs,\n","                           signature=\"tokens\",\n","                           as_dict=True)[\"sequence_output\"]\n","        return result\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_size)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"lymySRULyAEx","executionInfo":{"status":"ok","timestamp":1612358679698,"user_tz":180,"elapsed":5123,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["def initialize_vars():\n","  # initialize the session\n","  sess.run(tf.local_variables_initializer())\n","  sess.run(tf.global_variables_initializer())\n","  sess.run(tf.tables_initializer())\n","  tf.keras.backend.set_session(sess)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjVkzUzyFeXr","executionInfo":{"status":"ok","timestamp":1612358679700,"user_tz":180,"elapsed":4005,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["def build_model(dropout_rate = 0.15):\n","  # model inputs\n","\n","    in_id      = layers.Input(shape=(MAX_SEQ_LEN,), name=\"input_ids\")\n","    in_mask    = layers.Input(shape=(MAX_SEQ_LEN,), name=\"input_masks\")\n","    in_segment = layers.Input(shape=(MAX_SEQ_LEN,), name=\"segment_ids\")\n","\n","    in_bert    = [in_id, in_mask, in_segment]\n","\n","    # BERT layer\n","\n","    l_bert = BERT(finetune_cells=TUNE_CELLS,\n","                  bert_path=BERT_PATH,\n","                  debug=False)(in_bert)\n","\n","    # fully-connected layer and output\n","\n","    l_pool = layers.GlobalMaxPooling1D()(l_bert)\n","    dropout = layers.Dropout(rate=dropout_rate)(l_pool)\n","    out_pred = layers.Dense(1, activation=\"sigmoid\")(dropout)\n","    \n","    model = tf.keras.models.Model(inputs=in_bert, outputs=out_pred)\n","\n","    \"\"\"opt = tf.keras.optimizers.Adam(lr=learning_rate)\n","    if MIXED_PRECISION:\n","        opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)\"\"\"\n","\n","    model.compile(loss=\"binary_crossentropy\",\n","                  optimizer=\"SGD\",\n","                  metrics=[\"accuracy\"])\n","\n","    #model.summary()\n","  \n","    initialize_vars()\n","    return model"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"alFU8wVsuApK","executionInfo":{"status":"ok","timestamp":1612359149118,"user_tz":180,"elapsed":1259,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["def build_and_train_model(dropout_rate = 0.15,\n","                batch_s = 32, verbose = 0, save_model = False, epchs = 5, opti = True):  \n","    \n","    model = build_model(dropout_rate)\n","\n","    history = model.fit([train_input_ids, train_input_masks, train_segment_ids], \n","          train_labels, validation_split=VAL_SPLIT,\n","          workers=2, use_multiprocessing=True,\n","          epochs=epchs, batch_size=int(batch_s),\n","          verbose = verbose)\n","\n","    #if save_model:\n","    #  model.save(format(env_url/'rnn-bert-usrecog.h5'), \"w+\")  \n","\n","    if opti:\n","      return history.history[\"val_acc\"][-1]\n","    else:  \n","      return model,history;"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8pYloVPGAbH","executionInfo":{"status":"ok","timestamp":1612358680910,"user_tz":180,"elapsed":564,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}}},"source":["def load_model():\n","  # Clear and load model\n","  model = None\n","  model = build_model()\n","  model.load_weights(format(env_url/'rnn-bert-usrecog.h5'))\n","  return model"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"q86LBpqG0fFq"},"source":["def optimization():\n","    hypScope = {\n","        'dropout_rate': (0.1,0.3),\n","        'batch_s': (32,64)\n","    }\n","    bo = BayesianOptimization(build_and_train_model, hypScope)\n","    bo.maximize()\n","    print(bo.max)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFKRMYA15w_2"},"source":["#optimization()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5FV89xyrkFy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612359497370,"user_tz":180,"elapsed":344753,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"18b42b58-3d8e-4d13-dd27-73eae089d64c"},"source":["model,history = build_and_train_model(batch_s=60, dropout_rate= 0.25, verbose=1, epchs = 7 , save_model = True, opti = False)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method BERT.call of <__main__.BERT object at 0x7fc4a9aa6320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method BERT.call of <__main__.BERT object at 0x7fc4a9aa6320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BERT.call of <__main__.BERT object at 0x7fc4a9aa6320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 3917 samples, validate on 1680 samples\n","Epoch 1/7\n","3917/3917 [==============================] - 65s 17ms/sample - loss: 0.3734 - acc: 0.8409 - val_loss: 0.3476 - val_acc: 0.8685\n","Epoch 2/7\n","3917/3917 [==============================] - 50s 13ms/sample - loss: 0.2052 - acc: 0.9221 - val_loss: 0.2907 - val_acc: 0.8881\n","Epoch 3/7\n","3917/3917 [==============================] - 44s 11ms/sample - loss: 0.1514 - acc: 0.9449 - val_loss: 0.1398 - val_acc: 0.9464\n","Epoch 4/7\n","3917/3917 [==============================] - 44s 11ms/sample - loss: 0.1208 - acc: 0.9581 - val_loss: 0.1066 - val_acc: 0.9631\n","Epoch 5/7\n","3917/3917 [==============================] - 44s 11ms/sample - loss: 0.1032 - acc: 0.9676 - val_loss: 0.1591 - val_acc: 0.9411\n","Epoch 6/7\n","3917/3917 [==============================] - 44s 11ms/sample - loss: 0.1088 - acc: 0.9640 - val_loss: 0.1014 - val_acc: 0.9631\n","Epoch 7/7\n","3917/3917 [==============================] - 44s 11ms/sample - loss: 0.0990 - acc: 0.9666 - val_loss: 0.1211 - val_acc: 0.9565\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V3tj4AVmyph7"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphics(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_' + string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUPiWJRhilhx"},"source":["plot_graphics(history, 'acc')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKVax1EYiDQu"},"source":["plot_graphics(history, 'loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qI2ZPt_GJ6C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612355456585,"user_tz":180,"elapsed":19155,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"7c6863b0-f82d-489e-c4cb-b524dd38d7cc"},"source":["if (env_url/'rnn-bert-usrecog.h5').exists():\n","  model = load_model()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method BERT.call of <__main__.BERT object at 0x7fd1c9748dd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method BERT.call of <__main__.BERT object at 0x7fd1c9748dd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BERT.call of <__main__.BERT object at 0x7fd1c9748dd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7sVxlvCJiruq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612359553634,"user_tz":180,"elapsed":28303,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"c47a61f0-c05c-4506-a5c0-3eeb0519588f"},"source":["csvValidationfile = codecs.open(env_url/'validation.csv', 'r', encoding='utf-8', errors='ignore')\n","reader = csv.DictReader(csvValidationfile, delimiter=',')\n","\n","test_texts = data_test\n","labels = labels_test\n","\n","''''for row in reader:\n","  test_texts.append(row['Summary'].lower())\n","  labels.append(int(row['UserStory'].lower()))\n","\n","csvfile.close()'''\n","\n","preprop_text = [' '.join(t.split()[0:MAX_SEQ_LEN]) for t in test_texts]\n","preprop_text = np.array(preprop_text, dtype=object)[:, np.newaxis]\n","\n","test_examples = convert_test_text_to_examples(preprop_text)\n","\n","feat = convert_examples_to_features(tokenizer,\n","                                    test_examples,\n","                                    max_seq_length=MAX_SEQ_LEN)\n","\n","(test_input_ids,test_input_masks,test_segment_ids,test_labels) = feat\n","\n","predicted = model.predict([test_input_ids, test_input_masks, test_segment_ids])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Converting examples to features: 100%|██████████| 2399/2399 [00:00<00:00, 3093.13it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RraVW2-aMFxa","executionInfo":{"status":"ok","timestamp":1612359554515,"user_tz":180,"elapsed":864,"user":{"displayName":"Francisco Javier Peña","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGebPQf9SW5Fzw-LTtXvAA_8iU9-q1MYcbXKiIiA=s64","userId":"11348427767447057236"}},"outputId":"1f494df0-660a-441a-ec4a-192f0909f918"},"source":["for i in range(predicted.size):\r\n","  if (predicted[i] > 0.8):\r\n","    predicted[i] = 1\r\n","  else:\r\n","    predicted[i] = 0\r\n","\r\n","from sklearn.metrics import f1_score\r\n","f1_score(labels_test, predicted, average='macro')"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.965677100512961"]},"metadata":{"tags":[]},"execution_count":22}]}]}